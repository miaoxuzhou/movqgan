# Training configuration for MoVQGAN 102M model

ckpt_path: ''
wandb_project_name: 'movqgan-102M'

trainer:
  log_every_n_steps: 10
  precision: 32
  gradient_clip_val: 1.0
  gradient_clip_algorithm: 'value'
  num_nodes: 1
  accelerator: 'gpu'
  strategy: 'ddp'
  devices: 1                         # Using single GPU for 102M
  max_steps: 9999999
  replace_sampler_ddp: false

ModelCheckpoint:
  dirpath: './checkpoints/movqgan_102M'
  filename: "step_{step:07d}"
  save_top_k: -1
  every_n_train_steps: 5000
  save_last: true

model:
  target: movqgan.models.movq.MOVQ
  params:
    learning_rate: 0.0001
    ema_decay: 0.9999
    embed_dim: 4
    n_embed: 16384
    monitor: val/rec_loss
    
    ddconfig:
      double_z: false
      z_channels: 4
      resolution: 256
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult: [1, 2, 2, 4]
      num_res_blocks: 4              # More residual blocks (102M)
      attn_resolutions: [32]
      dropout: 0.0
    
    lossconfig:
      target: movqgan.losses.vqgan_loss.VQGANLoss
      params:
        disc_conditional: false
        disc_in_channels: 3
        disc_num_layers: 2
        disc_start: 1
        disc_weight: 0.8
        codebook_weight: 1.0
        perceptual_weight: 1.0

data:
  train:
    df_path: ./dataset.csv
    image_size: 256
    batch_size: 10                   # Slightly smaller batch for larger model
    shuffle: true
    num_workers: 12